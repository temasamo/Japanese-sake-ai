import { NextApiRequest, NextApiResponse } from "next";

type ChatCompletionMessage = {
  role: "system" | "user" | "assistant";
  content: string;
};

type PreferenceData = {
  taste_score: number;
  aroma_score: number;
  temperature_preference?: "cold" | "warm" | "room";
  price_range?: "low" | "mid" | "high";
  context_tag?: "meal" | "reward" | "gift" | "study";
  mode?: "self" | "gift" | "travel" | "media";
};

type ResultResponse = {
  type: "result";
  message: string;
  data: PreferenceData;
};

type FollowupResponse = {
  type: "followup";
  message: string;
  data: null;
};

type APIResponse = ResultResponse | FollowupResponse;

type OpenAIResponse = {
  choices: Array<{
    message: {
      content: string | null;
      function_call?: {
        name: string;
        arguments: string;
      };
    };
    finish_reason: string;
  }>;
};

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<APIResponse | { error: string }>
) {
  if (req.method !== "POST") {
    return res.status(405).json({ error: "Method not allowed" });
  }

  const { messages } = req.body;

  if (!messages || !Array.isArray(messages)) {
    return res.status(400).json({ error: "Messages array is required" });
  }

  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    return res.status(500).json({ error: "OpenAI API key not configured" });
  }

  try {
    // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
    const systemPrompt = `ã‚ãªãŸã¯æ—¥æœ¬é…’ã‚½ãƒ ãƒªã‚¨AIã§ã™ã€‚ğŸ¶
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±ã‚’é€šã˜ã¦ã€æ—¥æœ¬é…’ã®å—œå¥½ã‚’ç†è§£ã—ã¦ãã ã•ã„ã€‚
ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§è¦ªã—ã¿ã‚„ã™ã„ãƒˆãƒ¼ãƒ³ã§ä¼šè©±ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚’è‡ªç„¶ã«å¼•ãå‡ºã—ã¦ãã ã•ã„ã€‚
æ›–æ˜§ãªå›ç­”ï¼ˆã€Œã©ã£ã¡ã§ã‚‚ã€ã€Œã‚ã‹ã‚‰ãªã„ã€ãªã©ï¼‰ã®å ´åˆã¯ã€å…·ä½“çš„ãªè³ªå•ã‚’ã—ã¦æƒ…å ±ã‚’é›†ã‚ã¦ãã ã•ã„ã€‚`;

    const openaiMessages: ChatCompletionMessage[] = [
      { role: "system", content: systemPrompt },
      ...messages,
    ];

    // Function callingã®å®šç¾©
    const functions = [
      {
        name: "extract_preferences",
        description: "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã‚’JSONå½¢å¼ã«ã¾ã¨ã‚ã‚‹",
        parameters: {
          type: "object",
          properties: {
            taste_score: {
              type: "number",
              description: "ç”˜å£åº¦åˆã„ï¼ˆ0=è¾›å£ã€1=ç”˜å£ï¼‰",
              minimum: 0,
              maximum: 1,
            },
            aroma_score: {
              type: "number",
              description: "é¦™ã‚Šã®å¼·ã•ï¼ˆ0=æ§ãˆã‚ã€1=ãƒ•ãƒ«ãƒ¼ãƒ†ã‚£ãƒ¼/è¯ã‚„ã‹ï¼‰",
              minimum: 0,
              maximum: 1,
            },
            temperature_preference: {
              type: "string",
              enum: ["cold", "warm", "room"],
              description: "æ¸©åº¦ã®å¥½ã¿ï¼ˆcold=å†·ã‚„ã€warm=ç‡—ã€room=å¸¸æ¸©ï¼‰",
            },
            price_range: {
              type: "string",
              enum: ["low", "mid", "high"],
              description: "ä¾¡æ ¼å¸¯ï¼ˆlow=ã€œ3000å††ã€mid=3000ã€œ8000å††ã€high=8000å††ã€œï¼‰",
            },
            context_tag: {
              type: "string",
              enum: ["meal", "reward", "gift", "study"],
              description: "é£²ã‚€ã‚·ãƒ¼ãƒ³ï¼ˆmeal=é£Ÿäº‹ã€reward=ã”è¤’ç¾ã€gift=è´ˆã‚Šç‰©ã€study=å‹‰å¼·/è¶£å‘³ï¼‰",
            },
            mode: {
              type: "string",
              enum: ["self", "gift", "travel", "media"],
              description: "ç”¨é€”ï¼ˆself=è‡ªåˆ†ç”¨ã€gift=è´ˆã‚Šç‰©ã€travel=æ—…è¡Œã€media=ãƒ¡ãƒ‡ã‚£ã‚¢/æƒ…å ±åé›†ï¼‰",
            },
          },
          required: ["taste_score", "aroma_score"],
        },
      },
    ];

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: openaiMessages,
        functions: functions,
        function_call: { name: "extract_preferences" },
        max_tokens: 500,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.text();
      console.error("OpenAI API error:", errorData);
      return res.status(500).json({ error: "OpenAI API request failed" });
    }

    const data: OpenAIResponse = await response.json();
    const choice = data.choices[0];

    if (!choice) {
      return res.status(500).json({ error: "No response from OpenAI" });
    }

    const message = choice.message;

    // Function callãŒç™ºç«ã—ãŸå ´åˆï¼ˆJSONç¢ºå®šï¼‰
    if (message.function_call && message.function_call.name === "extract_preferences") {
      try {
        const functionArgs = JSON.parse(message.function_call.arguments) as PreferenceData;

        // å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼
        if (
          typeof functionArgs.taste_score !== "number" ||
          typeof functionArgs.aroma_score !== "number"
        ) {
          throw new Error("Required fields missing");
        }

        // å€¤ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
        if (
          functionArgs.taste_score < 0 ||
          functionArgs.taste_score > 1 ||
          functionArgs.aroma_score < 0 ||
          functionArgs.aroma_score > 1
        ) {
          throw new Error("Invalid score range");
        }

        const result: ResultResponse = {
          type: "result",
          message: "å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚",
          data: functionArgs,
        };

        return res.status(200).json(result);
      } catch (parseError) {
        console.error("Function call parsing error:", parseError);
        // ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã¨ã—ã¦æ‰±ã†
        const followup: FollowupResponse = {
          type: "followup",
          message: "ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚ç”˜å£ã¨è¾›å£ã€ã©ã¡ã‚‰ã®æ—¥æœ¬é…’ã‚’é£²ã‚€ã“ã¨ãŒå¤šã„ã§ã™ã‹ï¼Ÿ",
          data: null,
        };
        return res.status(200).json(followup);
      }
    }

    // Function callãŒç™ºç«ã—ãªã‹ã£ãŸå ´åˆï¼ˆæ›–æ˜§å›ç­”ãƒ»å†è³ªå•ï¼‰
    const aiMessage = message.content || "ã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚";
    const followup: FollowupResponse = {
      type: "followup",
      message: aiMessage,
      data: null,
    };

    return res.status(200).json(followup);
  } catch (error) {
    console.error("Chat diagnose API error:", error);
    return res.status(500).json({ error: "Internal server error" });
  }
}

